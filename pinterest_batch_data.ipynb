{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a1fb5fa-bc6c-42e1-b6fb-99993748980f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "import urllib\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "434d04ac-6d7e-42cf-b3cc-57d84312c9b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the path to the Delta table\n",
    "delta_table_path = \"dbfs:/user/hive/warehouse/authentication_credentials\"\n",
    "\n",
    "# Read the Delta table to a Spark DataFrame\n",
    "aws_keys_df = spark.read.format(\"delta\").load(delta_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbebc179-22d0-457e-8c25-1b63bda9dd0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the AWS access key and secret key from the spark dataframe\n",
    "ACCESS_KEY = aws_keys_df.select('Access key ID').collect()[0]['Access key ID']\n",
    "SECRET_KEY = aws_keys_df.select('Secret access key').collect()[0]['Secret access key']\n",
    "# Encode the secrete key\n",
    "ENCODED_SECRET_KEY = urllib.parse.quote(string=SECRET_KEY, safe=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c1d731a-f3ce-422d-a657-1e9ae6997ce1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# AWS S3 bucket name\n",
    "AWS_S3_BUCKET = \"0afff69adbe3-bucket\"\n",
    "# Mount name for the bucket\n",
    "MOUNT_NAME = \"/mnt/mount_name\"\n",
    "# Source url\n",
    "SOURCE_URL = \"s3n://{0}:{1}@{2}\".format(ACCESS_KEY, ENCODED_SECRET_KEY, AWS_S3_BUCKET)\n",
    "# Mount the drive\n",
    "# dbutils.fs.mount(SOURCE_URL, MOUNT_NAME) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9a3363e-814f-4ef9-ba18-65d8285a7fb4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Disable format checks during the reading of Delta tables\n",
    "SET spark.databricks.delta.formatCheck.enabled=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c73900ee-238b-4532-9e6b-32e23a2b83da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File location and type\n",
    "# Asterisk(*) indicates reading all the content of the specified file that have .json extension\n",
    "file_location = \"/mnt/mount_name/topics/topics/1209b9ad90a5.pin/partition=0/*.json\" \n",
    "file_type = \"json\"\n",
    "# Ask Spark to infer the schema\n",
    "infer_schema = \"true\"\n",
    "# Read in JSONs from mounted S3 bucket\n",
    "df_pin = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".load(file_location)\n",
    "# Display Spark dataframe to check its content\n",
    "display(df_pin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c83eceb5-2644-45d5-a7ae-5d55266b3fa1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_df_pin(df_pin):\n",
    "    \"\"\"\n",
    "    Cleans and transforms the pin DataFrame by performing the following steps:\n",
    "    \n",
    "    1. Replace empty entries and entries with no relevant data in each column with None.\n",
    "    2. Convert the `follower_count` column to integers, ensuring every entry is a number.\n",
    "    3. Ensure numeric data columns have appropriate numeric data types.\n",
    "    4. Clean the data in the `save_location` column to include only the save location path.\n",
    "    5. Rename the `index` column to `ind`.\n",
    "    6. Reorder the DataFrame columns.\n",
    "\n",
    "    Parameters:\n",
    "    df_pin (DataFrame): Input DataFrame containing Pinterest data.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: Cleaned and transformed DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the conditions for replacing invalid entries with None\n",
    "    conditions = [\n",
    "        (\"\", None),\n",
    "        (\"No description available Story format\", None),\n",
    "        (\"User Info Error\", None),\n",
    "        (\"Image src error.\", None),\n",
    "        (\"N,o, ,T,a,g,s, ,A,v,a,i,l,a,b,l,e\", None),\n",
    "        (\"No Title Data Available\", None)\n",
    "    ]\n",
    "\n",
    "    # Function to apply multiple conditions to a column\n",
    "    def apply_conditions(col, conditions):\n",
    "        return reduce(lambda acc, cond: F.when(F.col(col) == cond[0], cond[1]).otherwise(acc), conditions, F.col(col))\n",
    "\n",
    "    # Apply the conditions to each column\n",
    "    df_pin = df_pin.select([apply_conditions(c, conditions).alias(c) for c in df_pin.columns])\n",
    "\n",
    "    # Remove non-numeric characters from follower_count and convert to integer\n",
    "    df_pin = df_pin.withColumn(\"follower_count\", F.regexp_replace(F.col(\"follower_count\"), \"[^0-9]\", \"\"))\n",
    "    df_pin = df_pin.withColumn(\"follower_count\", F.col(\"follower_count\").cast(IntegerType()))\n",
    "\n",
    "    # Ensure numeric columns have the correct data type\n",
    "    numeric_columns = ['follower_count', 'downloaded', 'index']\n",
    "    for col in numeric_columns:\n",
    "        df_pin = df_pin.withColumn(col, F.col(col).cast(IntegerType()))\n",
    "\n",
    "    # Clean the save_location column\n",
    "    df_pin = df_pin.withColumn(\"save_location\", F.regexp_replace(F.col(\"save_location\"), \"^Local save in \", \"\"))\n",
    "\n",
    "    # Rename the index column to ind\n",
    "    df_pin = df_pin.withColumnRenamed(\"index\", \"ind\")\n",
    "\n",
    "    # Reorder the DataFrame columns\n",
    "    df_pin = df_pin.select(\"ind\", \"unique_id\", \"title\", \"description\", \"follower_count\",\n",
    "                           \"poster_name\", \"tag_list\", \"is_image_or_video\", \"image_src\",\n",
    "                           \"save_location\", \"category\")\n",
    "    \n",
    "    return df_pin\n",
    "\n",
    "# Apply the cleaning function to the df_pin DataFrame\n",
    "df_pin = clean_df_pin(df_pin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63c5336c-febd-42b9-9365-66bafa28dc5f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File location and type\n",
    "# Asterisk(*) indicates reading all the content of the specified file that have .json extension\n",
    "file_location = \"/mnt/mount_name/topics/topics/1209b9ad90a5.geo/partition=0/*.json\" \n",
    "file_type = \"json\"\n",
    "# Ask Spark to infer the schema\n",
    "infer_schema = \"true\"\n",
    "# Read in JSONs from mounted S3 bucket\n",
    "df_geo = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".load(file_location)\n",
    "# Display Spark dataframe to check its content\n",
    "display(df_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d50f788d-a062-4158-9c37-77275e7cb434",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_df_geo(df_geo):\n",
    "    \"\"\"\n",
    "    Cleans and transforms the geo DataFrame by performing the following steps:\n",
    "    \n",
    "    1. Create a new column 'coordinates' that contains an array based on the 'latitude' and 'longitude' columns.\n",
    "    2. Drop the 'latitude' and 'longitude' columns from the DataFrame.\n",
    "    3. Convert the 'timestamp' column from a string to a timestamp data type.\n",
    "    4. Reorder the DataFrame columns to have the specified column order: 'ind', 'country', 'coordinates', 'timestamp'.\n",
    "\n",
    "    Parameters:\n",
    "    df_geo (DataFrame): Input DataFrame containing geolocation data.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: Cleaned and transformed DataFrame.\n",
    "    \"\"\"\n",
    "    # Create a new column 'coordinates' that contains an array based on the 'latitude' and 'longitude' columns\n",
    "    df_geo = df_geo.withColumn(\"coordinates\", F.array(\"latitude\", \"longitude\"))\n",
    "\n",
    "    # Drop the 'latitude' and 'longitude' columns from the DataFrame\n",
    "    df_geo = df_geo.drop(\"latitude\", \"longitude\")\n",
    "\n",
    "    # Convert the 'timestamp' column from a string to a timestamp data type\n",
    "    df_geo = df_geo.withColumn(\"timestamp\", F.col(\"timestamp\").cast(\"timestamp\"))\n",
    "\n",
    "    # Reorder the DataFrame columns to have the specified column order\n",
    "    df_geo = df_geo.select(\"ind\", \"country\", \"coordinates\", \"timestamp\")\n",
    "\n",
    "    return df_geo\n",
    "\n",
    "# Apply the cleaning function to the df_geo DataFrame\n",
    "df_geo = clean_df_geo(df_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "810649f2-fc2b-4017-b9ff-e1f28ea98e16",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File location and type\n",
    "# Asterisk(*) indicates reading all the content of the specified file that have .json extension\n",
    "file_location = \"/mnt/mount_name/topics/topics/1209b9ad90a5.user/partition=0/*.json\" \n",
    "file_type = \"json\"\n",
    "# Ask Spark to infer the schema\n",
    "infer_schema = \"true\"\n",
    "# Read in JSONs from mounted S3 bucket\n",
    "df_user = spark.read.format(file_type) \\\n",
    ".option(\"inferSchema\", infer_schema) \\\n",
    ".load(file_location)\n",
    "# Display Spark dataframe to check its content\n",
    "display(df_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "776e4ef1-07a9-4c9c-8660-4103eefc3339",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_df_user(df_user):\n",
    "    \"\"\"\n",
    "    Cleans and transforms the user DataFrame by performing the following steps:\n",
    "    \n",
    "    1. Create a new column 'user_name' that concatenates 'first_name' and 'last_name'.\n",
    "    2. Drop the 'first_name' and 'last_name' columns from the DataFrame.\n",
    "    3. Convert the 'date_joined' column from a string to a timestamp data type.\n",
    "    4. Reorder the DataFrame columns to have the specified column order: 'ind', 'user_name', 'age', 'date_joined'.\n",
    "\n",
    "    Parameters:\n",
    "    df_user (DataFrame): Input DataFrame containing user data.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: Cleaned and transformed DataFrame.\n",
    "    \"\"\"\n",
    "    # Create a new column 'user_name' that concatenates 'first_name' and 'last_name'\n",
    "    df_user = df_user.withColumn(\"user_name\", F.concat_ws(\" \", F.col(\"first_name\"), F.col(\"last_name\")))\n",
    "\n",
    "    # Drop the 'first_name' and 'last_name' columns from the DataFrame\n",
    "    df_user = df_user.drop(\"first_name\", \"last_name\")\n",
    "\n",
    "    # Convert the 'date_joined' column from a string to a timestamp data type\n",
    "    df_user = df_user.withColumn(\"date_joined\", F.col(\"date_joined\").cast(\"timestamp\"))\n",
    "\n",
    "    # Reorder the DataFrame columns to have the specified column order\n",
    "    df_user = df_user.select(\"ind\", \"user_name\", \"age\", \"date_joined\")\n",
    "    \n",
    "    return df_user\n",
    "\n",
    "# Apply the cleaning function to the df_user DataFrame\n",
    "df_user = clean_df_user(df_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "913c1f51-1922-4c25-8a1d-0ff7a61efead",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Register the DataFrames as temporary views\n",
    "CREATE OR REPLACE TEMPORARY VIEW pin_view AS\n",
    "SELECT ind, category\n",
    "FROM df_pin;\n",
    "\n",
    "CREATE OR REPLACE TEMPORARY VIEW geo_view AS\n",
    "SELECT ind, country\n",
    "FROM df_geo;\n",
    "\n",
    "-- Join the pin and geo views on the common column 'ind'\n",
    "CREATE OR REPLACE TEMPORARY VIEW pin_geo_join AS\n",
    "SELECT g.country, p.category\n",
    "FROM pin_view p\n",
    "JOIN geo_view g\n",
    "ON p.ind = g.ind;\n",
    "\n",
    "-- Perform group-wise counting to find the most popular category in each country\n",
    "CREATE OR REPLACE TEMPORARY VIEW popular_category_per_country AS\n",
    "SELECT country, category, COUNT(*) AS category_count\n",
    "FROM pin_geo_join\n",
    "GROUP BY country, category;\n",
    "\n",
    "-- Rank the categories within each country based on category count\n",
    "CREATE OR REPLACE TEMPORARY VIEW ranked_categories_per_country AS\n",
    "SELECT country, category, category_count,\n",
    "       ROW_NUMBER() OVER (PARTITION BY country ORDER BY category_count DESC) AS category_rank\n",
    "FROM popular_category_per_country;\n",
    "\n",
    "-- Filter the result to get only the most popular category in each country\n",
    "CREATE OR REPLACE TEMPORARY VIEW most_popular_category_per_country AS\n",
    "SELECT country, category, category_count\n",
    "FROM ranked_categories_per_country\n",
    "WHERE category_rank = 1;\n",
    "\n",
    "-- Convert the result to a DataFrame\n",
    "SELECT * FROM most_popular_category_per_country;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d82014ca-39bd-46b1-a1f7-751201e05744",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Register the DataFrames as temporary views\n",
    "CREATE OR REPLACE TEMPORARY VIEW pin_view AS\n",
    "SELECT ind, category\n",
    "FROM df_pin;\n",
    "\n",
    "CREATE OR REPLACE TEMPORARY VIEW geo_view AS\n",
    "SELECT ind, timestamp\n",
    "FROM df_geo;\n",
    "\n",
    "-- Join the pin and geo views on the common column 'ind'\n",
    "CREATE OR REPLACE TEMPORARY VIEW pin_geo_join AS\n",
    "SELECT p.category, g.timestamp\n",
    "FROM pin_view p\n",
    "JOIN geo_view g\n",
    "ON p.ind = g.ind;\n",
    "\n",
    "-- Filter the data for posts between 2018 and 2022\n",
    "CREATE OR REPLACE TEMPORARY VIEW filtered_posts AS\n",
    "SELECT category, timestamp\n",
    "FROM pin_geo_join\n",
    "WHERE YEAR(timestamp) BETWEEN 2018 AND 2022;\n",
    "\n",
    "-- Extract the year from the timestamp column\n",
    "CREATE OR REPLACE TEMPORARY VIEW posts_with_year AS\n",
    "SELECT category, YEAR(timestamp) AS post_year\n",
    "FROM filtered_posts;\n",
    "\n",
    "-- Perform group-wise counting to find the number of posts for each category in each year\n",
    "CREATE OR REPLACE TEMPORARY VIEW category_post_count AS\n",
    "SELECT post_year, category, COUNT(*) AS category_count\n",
    "FROM posts_with_year\n",
    "GROUP BY post_year, category;\n",
    "\n",
    "-- Convert the result to a DataFrame\n",
    "SELECT * FROM category_post_count\n",
    "ORDER BY post_year;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d48a09a3-fcfd-4450-96a2-d67e72c3410c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Register the DataFrames as temporary views\n",
    "CREATE OR REPLACE TEMPORARY VIEW user_view AS\n",
    "SELECT ind, user_name\n",
    "FROM df_user;\n",
    "\n",
    "CREATE OR REPLACE TEMPORARY VIEW geo_view AS\n",
    "SELECT ind, country\n",
    "FROM df_geo;\n",
    "\n",
    "CREATE OR REPLACE TEMPORARY VIEW pin_view AS\n",
    "SELECT ind, poster_name, follower_count\n",
    "FROM df_pin;\n",
    "\n",
    "-- Join the views on the common column 'ind'\n",
    "CREATE OR REPLACE TEMPORARY VIEW join_view AS\n",
    "SELECT u.user_name, g.country, p.poster_name, p.follower_count\n",
    "FROM user_view u\n",
    "JOIN geo_view g ON u.ind = g.ind\n",
    "JOIN pin_view p ON p.ind = g.ind;\n",
    "\n",
    "-- Rank the users within each country based on follower_count\n",
    "CREATE OR REPLACE TEMPORARY VIEW ranked_users_per_country AS\n",
    "SELECT country, user_name, poster_name, follower_count,\n",
    "       ROW_NUMBER() OVER (PARTITION BY country ORDER BY follower_count DESC) AS user_rank\n",
    "FROM join_view;\n",
    "\n",
    "-- Filter the result to get only the user with the most followers in each country\n",
    "CREATE OR REPLACE TEMPORARY VIEW user_with_most_followers_per_country AS\n",
    "SELECT country, poster_name, follower_count\n",
    "FROM ranked_users_per_country\n",
    "WHERE user_rank = 1;\n",
    "\n",
    "-- Convert the result to a DataFrame\n",
    "SELECT * FROM user_with_most_followers_per_country;\n",
    "\n",
    "-- Perform group-wise counting to find the user with the most followers in each country\n",
    "CREATE OR REPLACE TEMPORARY VIEW country_with_user_most_followers AS\n",
    "SELECT country, MAX(follower_count) AS max_follower_count\n",
    "FROM user_with_most_followers_per_country\n",
    "GROUP BY country;\n",
    "\n",
    "-- Find the country with the user with the most followers\n",
    "CREATE OR REPLACE TEMPORARY VIEW country_with_most_followers AS\n",
    "SELECT c.country, u.poster_name, u.follower_count\n",
    "FROM user_with_most_followers_per_country u\n",
    "JOIN country_with_user_most_followers c\n",
    "ON u.country = c.country AND u.follower_count = c.max_follower_count;\n",
    "\n",
    "-- Convert the result to a DataFrame\n",
    "SELECT * FROM country_with_most_followers;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bd74403-cdf1-4d23-97dd-d92d618bfc90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Register the DataFrames as temporary views\n",
    "CREATE OR REPLACE TEMPORARY VIEW user_view AS\n",
    "SELECT ind, user_name\n",
    "FROM df_user;\n",
    "\n",
    "CREATE OR REPLACE TEMPORARY VIEW geo_view AS\n",
    "SELECT ind, country\n",
    "FROM df_geo;\n",
    "\n",
    "CREATE OR REPLACE TEMPORARY VIEW pin_view AS\n",
    "SELECT ind, poster_name, follower_count\n",
    "FROM df_pin;\n",
    "\n",
    "-- Join the views on the common column 'ind'\n",
    "CREATE OR REPLACE TEMPORARY VIEW join_view AS\n",
    "SELECT u.user_name, g.country, p.poster_name, p.follower_count\n",
    "FROM user_view u\n",
    "JOIN geo_view g ON u.ind = g.ind\n",
    "JOIN pin_view p ON p.ind = g.ind;\n",
    "\n",
    "-- Rank the users within each country based on follower_count\n",
    "CREATE OR REPLACE TEMPORARY VIEW ranked_users_per_country AS\n",
    "SELECT country, user_name, poster_name, follower_count,\n",
    "       ROW_NUMBER() OVER (PARTITION BY country ORDER BY follower_count DESC) AS user_rank\n",
    "FROM join_view;\n",
    "\n",
    "-- Filter the result to get only the user with the most followers in each country\n",
    "CREATE OR REPLACE TEMPORARY VIEW user_with_most_followers_per_country AS\n",
    "SELECT country, poster_name, follower_count\n",
    "FROM ranked_users_per_country\n",
    "WHERE user_rank = 1;\n",
    "\n",
    "-- Perform group-wise counting to find the user with the most followers in each country\n",
    "CREATE OR REPLACE TEMPORARY VIEW country_with_user_most_followers AS\n",
    "SELECT country, MAX(follower_count) AS max_follower_count\n",
    "FROM user_with_most_followers_per_country\n",
    "GROUP BY country;\n",
    "\n",
    "-- Find the country with the user with the most followers\n",
    "CREATE OR REPLACE TEMPORARY VIEW country_with_most_followers AS\n",
    "SELECT c.country, u.follower_count\n",
    "FROM user_with_most_followers_per_country u\n",
    "JOIN country_with_user_most_followers c\n",
    "ON u.country = c.country AND u.follower_count = c.max_follower_count;\n",
    "\n",
    "-- Select the country with the highest number of followers\n",
    "CREATE OR REPLACE TEMPORARY VIEW country_with_highest_followers AS\n",
    "SELECT country, follower_count\n",
    "FROM country_with_most_followers\n",
    "ORDER BY follower_count DESC\n",
    "LIMIT 1;\n",
    "\n",
    "-- Convert the result to a DataFrame containing only the desired columns\n",
    "SELECT country, follower_count FROM country_with_highest_followers;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a733c7df-c999-45f2-8b28-050db4b63784",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Register the DataFrames as temporary views\n",
    "CREATE OR REPLACE TEMPORARY VIEW pin_view AS\n",
    "SELECT ind, category\n",
    "FROM df_pin;\n",
    "\n",
    "CREATE OR REPLACE TEMPORARY VIEW user_view AS\n",
    "SELECT ind, age\n",
    "FROM df_user;\n",
    "\n",
    "-- Join the views on the common column 'ind'\n",
    "CREATE OR REPLACE TEMPORARY VIEW join_view AS\n",
    "SELECT p.category, u.age\n",
    "FROM pin_view p\n",
    "JOIN user_view u\n",
    "ON p.ind = u.ind;\n",
    "\n",
    "-- Create age groups based on the age column\n",
    "CREATE OR REPLACE TEMPORARY VIEW age_groups AS\n",
    "SELECT *,\n",
    "       CASE \n",
    "           WHEN age >= 18 AND age <= 24 THEN '18-24'\n",
    "           WHEN age >= 25 AND age <= 35 THEN '25-35'\n",
    "           WHEN age >= 36 AND age <= 50 THEN '36-50'\n",
    "           WHEN age >= 51 THEN '+50'\n",
    "       END AS age_group\n",
    "FROM join_view;\n",
    "\n",
    "-- Perform group-wise counting to find the most popular category in each age group\n",
    "CREATE OR REPLACE TEMPORARY VIEW popular_category_by_age_group AS\n",
    "SELECT age_group, category, COUNT(*) AS category_count\n",
    "FROM age_groups\n",
    "GROUP BY age_group, category;\n",
    "\n",
    "-- Select the most popular category in each age group\n",
    "CREATE OR REPLACE TEMPORARY VIEW most_popular_category_per_age_group AS\n",
    "SELECT age_group, category, category_count,\n",
    "       ROW_NUMBER() OVER (PARTITION BY age_group ORDER BY category_count DESC) AS category_rank\n",
    "FROM popular_category_by_age_group;\n",
    "\n",
    "-- Filter the result to get only the most popular category in each age group\n",
    "CREATE OR REPLACE TEMPORARY VIEW result AS\n",
    "SELECT age_group, category, category_count\n",
    "FROM most_popular_category_per_age_group\n",
    "WHERE category_rank = 1;\n",
    "\n",
    "-- Convert the result to a DataFrame\n",
    "SELECT * FROM result;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "162c843a-e44c-4bf3-bb74-aeed1fe7d1a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Register the DataFrames as temporary views\n",
    "CREATE OR REPLACE TEMPORARY VIEW pin_view AS\n",
    "SELECT ind, follower_count\n",
    "FROM df_pin;\n",
    "\n",
    "CREATE OR REPLACE TEMPORARY VIEW user_view AS\n",
    "SELECT ind, age\n",
    "FROM df_user;\n",
    "\n",
    "-- Join the views on the common column 'ind'\n",
    "CREATE OR REPLACE TEMPORARY VIEW join_view AS\n",
    "SELECT p.follower_count, u.age\n",
    "FROM pin_view p\n",
    "JOIN user_view u\n",
    "ON p.ind = u.ind;\n",
    "\n",
    "-- Create age groups based on the age column\n",
    "CREATE OR REPLACE TEMPORARY VIEW age_groups AS\n",
    "SELECT *,\n",
    "       CASE \n",
    "           WHEN age >= 18 AND age <= 24 THEN '18-24'\n",
    "           WHEN age >= 25 AND age <= 35 THEN '25-35'\n",
    "           WHEN age >= 36 AND age <= 50 THEN '36-50'\n",
    "           ELSE '+50'\n",
    "       END AS age_group\n",
    "FROM join_view;\n",
    "\n",
    "-- Calculate the median follower count for each age group\n",
    "CREATE OR REPLACE TEMPORARY VIEW median_follower_count_per_age_group AS\n",
    "SELECT age_group,\n",
    "       percentile_approx(follower_count, 0.5) AS median_follower_count\n",
    "FROM age_groups\n",
    "GROUP BY age_group;\n",
    "\n",
    "-- Convert the result to a DataFrame\n",
    "SELECT * FROM median_follower_count_per_age_group;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c13f140-61fb-4954-8025-72203c70ee0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Register the DataFrame as a temporary view\n",
    "CREATE OR REPLACE TEMPORARY VIEW user_view AS\n",
    "SELECT date_joined\n",
    "FROM df_user;\n",
    "\n",
    "-- Extract the year from the date_joined column and filter for users who joined between 2015 and 2020\n",
    "CREATE OR REPLACE TEMPORARY VIEW filtered_users AS\n",
    "SELECT YEAR(date_joined) AS join_year\n",
    "FROM user_view\n",
    "WHERE YEAR(date_joined) BETWEEN 2015 AND 2020;\n",
    "\n",
    "-- Count the number of users who joined each year\n",
    "CREATE OR REPLACE TEMPORARY VIEW users_joined_per_year AS\n",
    "SELECT join_year, COUNT(*) AS number_users_joined\n",
    "FROM filtered_users\n",
    "GROUP BY join_year;\n",
    "\n",
    "-- Convert the result to a DataFrame\n",
    "SELECT * FROM users_joined_per_year;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e597ce0a-72d7-45be-a846-7aca110068c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Register the DataFrames as temporary views\n",
    "CREATE OR REPLACE TEMPORARY VIEW user_view AS\n",
    "SELECT ind, date_joined\n",
    "FROM df_user;\n",
    "\n",
    "CREATE OR REPLACE TEMPORARY VIEW pin_view AS\n",
    "SELECT ind, follower_count\n",
    "FROM df_pin;\n",
    "\n",
    "-- Join the views on the common column 'ind'\n",
    "CREATE OR REPLACE TEMPORARY VIEW join_view AS\n",
    "SELECT p.follower_count, u.date_joined\n",
    "FROM pin_view p\n",
    "JOIN user_view u\n",
    "ON p.ind = u.ind;\n",
    "\n",
    "-- Filter the data to include only users who joined between 2015 and 2020\n",
    "CREATE OR REPLACE TEMPORARY VIEW filtered_users AS\n",
    "SELECT follower_count, YEAR(date_joined) AS join_year\n",
    "FROM join_view\n",
    "WHERE YEAR(date_joined) BETWEEN 2015 AND 2020;\n",
    "\n",
    "-- Calculate the median follower count for users who joined between 2015 and 2020\n",
    "CREATE OR REPLACE TEMPORARY VIEW median_follower_count AS\n",
    "SELECT join_year,\n",
    "       percentile_approx(follower_count, 0.5) AS median_follower_count\n",
    "FROM filtered_users\n",
    "GROUP BY join_year;\n",
    "\n",
    "-- Convert the result to a DataFrame\n",
    "SELECT * FROM median_follower_count;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9e21947-fa90-41dd-ab07-5645d2401e27",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Register the DataFrames as temporary views\n",
    "CREATE OR REPLACE TEMPORARY VIEW user_view AS\n",
    "SELECT ind, date_joined, age\n",
    "FROM df_user;\n",
    "\n",
    "CREATE OR REPLACE TEMPORARY VIEW pin_view AS\n",
    "SELECT ind, follower_count\n",
    "FROM df_pin;\n",
    "\n",
    "-- Join the views on the common column 'ind'\n",
    "CREATE OR REPLACE TEMPORARY VIEW join_view AS\n",
    "SELECT p.follower_count, u.date_joined, u.age\n",
    "FROM pin_view p\n",
    "JOIN user_view u\n",
    "ON p.ind = u.ind;\n",
    "\n",
    "-- Filter the data to include only users who joined between 2015 and 2020\n",
    "CREATE OR REPLACE TEMPORARY VIEW filtered_users AS\n",
    "SELECT follower_count, YEAR(date_joined) AS join_year, age\n",
    "FROM join_view\n",
    "WHERE YEAR(date_joined) BETWEEN 2015 AND 2020;\n",
    "\n",
    "-- Create age groups based on the age column\n",
    "CREATE OR REPLACE TEMPORARY VIEW age_groups AS\n",
    "SELECT *,\n",
    "       CASE \n",
    "           WHEN age >= 18 AND age <= 24 THEN '18-24'\n",
    "           WHEN age >= 25 AND age <= 35 THEN '25-35'\n",
    "           WHEN age >= 36 AND age <= 50 THEN '36-50'\n",
    "           ELSE '+50'\n",
    "       END AS age_group\n",
    "FROM filtered_users;\n",
    "\n",
    "-- Calculate the median follower count for each age group\n",
    "CREATE OR REPLACE TEMPORARY VIEW median_follower_count_per_age_group AS\n",
    "SELECT age_group, join_year,\n",
    "       percentile_approx(follower_count, 0.5) AS median_follower_count\n",
    "FROM age_groups\n",
    "GROUP BY age_group, join_year;\n",
    "\n",
    "-- Convert the result to a DataFrame\n",
    "SELECT * FROM median_follower_count_per_age_group;\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 764650334901748,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "pinterest_batch_data",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
